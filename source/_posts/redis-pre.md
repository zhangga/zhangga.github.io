---
title: Redis常见面试题
date: 2019-03-27 19:52:43
tags:
  - 数据库
  - 面试
id: redis-pre
categories:
  - 笔记
---

和Redis结缘还是2011年刚开始实习，做的第一款游戏《部落战争》，
就是使用的Redis作为持久层和缓存。 当时对Redis的认识还比较浅，但是Redis的好多特性已经开始慢慢了解。

这里推荐一下大神的Redis公众号。付磊。快手同事，《Redis开发与运维》一书的作者，强烈推荐这本书，偏向实战，另外一本很有名的书《Redis设计与实现》更注重原理。两本书都非常值得好好读下。

<!--more-->

![Redis常见面试题 - 第1张  | 张嘎](https://i2.wp.com/192.144.167.243/blog/wp-content/uploads/4-576x1024.jpg?resize=640%2C1138)

![Redis常见面试题 - 第2张  | 张嘎](https://i2.wp.com/192.144.167.243/blog/wp-content/uploads/3-1-576x1024.jpg?resize=576%2C1024)

#### Memcached相比于Redis的主要特点有如下：

\1. 超高OPS：例如千万级别以上（线上千万OPS以上的Redis也存在）
\2. 多线程：抗热点能力强。
\3. 支持大value：例如Memcached 5支持100MB以上的value

但Memcached相比于Redis维护成本会更高，而且对于很多基础设施支持也不好（双机房、键值分析、内存优化、服务端高可用）。

最近发现KCC上出现Memcached滥用的情况

为防止滥用，必须满足如下规则才会开通：

\1. OPS: 超过100万
\2. big value：10MB+
\3. 明显热点
\4. CAS需求

**一、Redis常见的数据结构和使用场景**

(一)String 这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做**一些复杂的计数功能的缓存。**

(二)hash 这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做**单点登录**的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。

(三)list 使用List的数据结构，可以**做简单的消息队列的功能**。另外还有一个就是，可以利用lrange命令，**做基于redis的分页功能**，性能极佳，用户体验好。

(四)set 因为set堆放的是一堆不重复值的集合。所以可以做**全局去重的功能**。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。 另外，就是利用交集、并集、差集等操作，可以**计算共同喜好，全部的喜好，自己独有的喜好等功能**。

(五)sorted set sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做**排行榜应用，取TOP N操作**。另外，参照另一篇[《分布式之延时任务方案解析》](http://link.zhihu.com/?target=https%3A//www.cnblogs.com/rjzheng/p/8972725.html)，该文指出了sorted set可以用来做**延时任务**。最后一个应用就是可以做**范围查找**。

**二、Redis的hash怎么实现的**
满足以下两条件时：
1、键和值的长度都小于64字节
2、键值对数量小于512个
使用ziplist编码。不满足时转化为hashtable编码，并且这个转化过程是不可逆的。
hashtable的实现方式和Java的hashmap类似，数组上散列，散列冲突的使用链表，不同的是redis采用渐进式的rehash策略。
何为**渐进式rehash**？就是把拷贝节点数据的过程平摊到后续的操作中，而不是一次性拷贝。维护两张哈希表，1个索引来指示当前的rehash进度。
rehash是以bucket(桶)为基本单位进行渐进式的数据迁移的，每步完成一个bucket的迁移，直至所有数据迁移完毕。一个bucket对应哈希表数组中的一条entry链表。
**Java HashMap**的rehash，每次创建一个数组（哈希表），一次性将old表rehash过去。

**三、为什么不能用Redis做专门的持久化**
性价比：内存吃紧 ，海量数据在重启后加载耗时。RDB加载快。
权限控制。
数据完整：MySQL 在崩溃处理，数据恢复方面比reids好。
redis作为数据库查询功能太弱。数据KV弱于结构化。
数据隔离。

# Redis Cluster|功能限制

1.Key批量操作支持有限。目前只支持同slot内的key执行批量操作（如mget,mset）。

2.Key事务操作支持有限。只支持多key在同一个节点上的事务操作，多个key分布在不同节点上时无法使用事务功能。

3.Key作为数据分区的最小粒度，因此不能将一个大的键值对象如hash，list等映射到不同节点。

4.不支持多数据库空间，集群模式下只能使用db0空间。

5.复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。

# Redis Cluster高可用

提供了灵活的节点扩容和收缩方案，在不影响集群对外服务的情况下进行。
自动故障转移保证集群可以正常对外提供服务。主观下线，客观下线，投票选举策略。选出从节点替换主节点，保证集群高可用。

**下面是两篇引用的文章。https://zhuanlan.zhihu.com/p/59168140**

## 引言

## 为什么写这篇文章?

博主的[《分布式之消息队列复习精讲》](http://link.zhihu.com/?target=http%3A//www.cnblogs.com/rjzheng/p/8994962.html)得到了大家的好评，内心诚惶诚恐，想着再出一篇关于复习精讲的文章。但是还是要说明一下，复习精讲的文章偏面试准备，真正在开发过程中，还是脚踏实地，一步一个脚印，不要投机取巧。 考虑到绝大部分写业务的程序员，在实际开发中使用redis的时候，只会setvalue和getvalue两个操作，对redis整体缺乏一个认知。又恰逢博主某个同事下周要去培训redis，所以博主斗胆以redis为题材，对redis常见问题做一个总结，希望能够弥补大家的知识盲点。

## 复习要点?

本文围绕以下几点进行阐述

- 1、为什么使用redis
- 2、使用redis有什么缺点
- 3、单线程的redis为什么这么快
- 4、redis的数据类型，以及每种数据类型的使用场景
- 5、redis的过期策略以及内存淘汰机制
- 6、redis和数据库双写一致性问题
- 7、如何应对缓存穿透和缓存雪崩问题
- 8、如何解决redis的并发竞争问题

## 正文

## 1、为什么使用redis

**分析**:博主觉得在项目中使用redis，主要是从两个角度去考虑:**性能**和**并发**。当然，redis还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件(如zookpeer等)代替，并不是非要使用redis。因此，这个问题主要从性能和并发两个角度去答。

**回答**:如下所示，分为两点

**（一）性能** 如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够**迅速响应**。

![Redis常见面试题 - 第3张  | 张嘎](https://i0.wp.com/pic4.zhimg.com/80/v2-8200a2192b95b1596dc8d02c71b9abcf_hd.jpg?w=640&ssl=1)

**题外话：**忽然想聊一下这个**迅速响应**的标准。其实根据交互效果的不同，这个响应时间没有固定标准。不过曾经有人这么告诉我:”在理想状态下，我们的页面跳转需要在**瞬间**解决，对于页内操作则需要在**刹那**间解决。另外，超过**一弹指**的耗时操作要有进度提示，并且可以随时中止或取消，这样才能给用户最好的体验。” 那么**瞬间、刹那、一弹指**具体是多少时间呢？ 根据《摩诃僧祗律》记载

```
一刹那者为一念，二十念为一瞬，二十瞬为一弹指，二十弹指为一罗预，二十罗预为一须臾，一日一夜有三十须臾。
```

那么，经过周密的计算，一**瞬间**为0.36 秒,一**刹那**有 0.018 秒.一**弹指**长达 7.2 秒。

**（二）并发** 如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。

![Redis常见面试题 - 第4张  | 张嘎](https://i2.wp.com/pic3.zhimg.com/80/v2-ee0f4577491f13d82e185e7ef6aa8eae_hd.jpg?w=640&ssl=1)

## 2、使用redis有什么缺点

**分析**:大家用redis这么久，这个问题是必须要了解的，基本上使用redis都会碰到一些问题，常见的也就几个。

**回答**:主要是四个问题

- (一)缓存和数据库双写一致性问题
- (二)缓存雪崩问题
- (三)缓存击穿问题
- (四)缓存的并发竞争问题

这四个问题，我个人是觉得在项目中，比较常遇见的，具体解决方案，后文给出。

## 3、单线程的redis为什么这么快

**分析**:这个问题其实是对redis内部机制的一个考察。其实根据博主的面试经验，很多人其实都不知道redis是单线程工作模型。所以，这个问题还是应该要复习一下的。

**回答**:主要是以下三点 (一)纯内存操作 (二)单线程操作，避免了频繁的上下文切换 (三)采用了非阻塞**I/O多路复用机制**

**题外话：**我们现在要仔细的说一说I/O多路复用机制，因为这个说法实在是太通俗了，通俗到一般人都不懂是什么意思。博主打一个比方：小曲在S城开了一家快递店，负责同城快送服务。小曲因为资金限制，雇佣了**一批**快递员，然后小曲发现资金不够了，只够买**一辆**车送快递。

**经营方式一** 客户每送来一份快递，小曲就让一个快递员盯着，然后快递员开车去送快递。慢慢的小曲就发现了这种经营方式存在下述问题 – 几十个快递员基本上时间都花在了抢车上了，大部分快递员都处在闲置状态，谁抢到了车，谁就能去送快递 – 随着快递的增多，快递员也越来越多，小曲发现快递店里越来越挤，没办法雇佣新的快递员了 – 快递员之间的协调很花时间

综合上述缺点，小曲痛定思痛，提出了下面的经营方式

**经营方式二** 小曲只雇佣一个快递员。然后呢，客户送来的快递，小曲按**送达地点**标注好，然后**依次**放在一个地方。最后，那个快递员**依次**的去取快递，一次拿一个，然后开着车去送快递，送好了就回来拿下一个快递。

**对比** 上述两种经营方式对比，是不是明显觉得第二种，效率更高，更好呢。

在上述比喻中:

- 每个快递员——————>每个线程
- 每个快递——————–>每个socket(I/O流)
- 快递的送达地点————–>socket的不同状态
- 客户送快递请求————–>来自客户端的请求
- 小曲的经营方式————–>服务端运行的代码
- 一辆车———————->CPU的核数

于是我们有如下结论

1. 经营方式一就是传统的并发模型，每个I/O流(快递)都有一个新的线程(快递员)管理。
2. 经营方式二就是I/O多路复用。只有单个线程(一个快递员)，通过跟踪每个I/O流的状态(每个快递的送达地点)，来管理多个I/O流。

下面类比到真实的redis线程模型，如图所示

![Redis常见面试题 - 第5张  | 张嘎](https://i0.wp.com/pic1.zhimg.com/80/v2-fa81e4bb9560b8ac6470bfa322f36a98_hd.jpg?w=640&ssl=1)

参照上图，简单来说，就是。我们的redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。 需要说明的是，这个I/O多路复用机制，redis还提供了select、epoll、evport、kqueue等多路复用函数库，大家可以自行去了解。

## 5、redis的过期策略以及内存淘汰机制

**分析**:这个问题其实相当重要，到底redis有没用到家，这个问题就可以看出来。比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?

**回答**: redis采用的是定期删除+惰性删除策略。

**为什么不用定时删除策略?** 定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.

**定期删除+惰性删除是如何工作的呢?**

定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。 于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。

**采用定期删除+惰性删除就没其他问题了么?**

不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用**内存淘汰机制**。 在redis.conf中有一行配置

```
# maxmemory-policy volatile-lru
```

该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)

1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。**应该没人用吧。**

2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。**推荐使用，目前项目在用这种。**

3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。**应该也没人用吧，你不删最少使用Key,去随机删。**

4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。**这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐**

5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。**依然不推荐** 6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。**不推荐** ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。

## 6、redis和数据库双写一致性问题

**分析**:一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是**如果对数据有强一致性要求，不能放缓存。**我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说**降低不一致发生的概率**，无法完全避免。因此，有强一致性要求的数据，不能放缓存。

**回答**:[《分布式之数据库和缓存双写一致性方案解析》](http://link.zhihu.com/?target=https%3A//www.cnblogs.com/rjzheng/p/9041659.html)给出了详细的分析，在这里简单的说一说。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。

## 7、如何应对缓存穿透和缓存雪崩问题

**分析**:这两个问题，说句实在话，一般中小型传统软件企业，很难碰到这个问题。如果有大并发的项目，流量有几百万左右。这两个问题一定要深刻考虑。

**回答**:如下所示

**缓存穿透**，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。

**解决方案**: (一)利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 (二)采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做**缓存预热**(项目启动前，先加载缓存)操作。 (三)提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。

**缓存雪崩**，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。

**解决方案**: (一)给缓存的失效时间，加上一个随机值，避免集体失效。 (二)使用互斥锁，但是该方案吞吐量明显下降了。 (三)双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点 – I 从缓存A读数据库，有则直接返回 – II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。 – III 更新线程同时更新缓存A和缓存B。

## 8、如何解决redis的并发竞争key问题

**分析**:这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主**不推荐使用redis的事务机制。**因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，**redis的事务机制，十分鸡肋。**

**回答:**如下所示

(1)如果对这个key操作，**不要求顺序** 这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。

(2)如果对这个key操作，**要求顺序** 假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC. 期望按照key1的value值按照 valueA–>valueB–>valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下

```
系统A key 1 {valueA  3:00}
系统B key 1 {valueB  3:05}
系统C key 1 {valueC  3:10}
```

那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。

其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。



# [【原创】分布式之数据库和缓存双写一致性方案解析](https://www.cnblogs.com/rjzheng/p/9041659.html)

## 引言

### 为什么写这篇文章？

![Redis常见面试题 - 第6张  | 张嘎](https://i0.wp.com/images.cnblogs.com/cnblogs_com/rjzheng/1202350/o_getkeyflow.png?w=640&ssl=1)

首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。

但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。目前没有一篇全面的博客，对这几种方案进行解析。于是博主战战兢兢，顶着被大家喷的风险，写了这篇文章。

### 文章结构

本文由以下三个部分组成
1、讲解缓存更新策略
2、对每种策略进行缺点分析
3、针对缺点给出改进方案

## 正文

先做一个说明，从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。
在这里，我们讨论**三种**更新策略：

1. 先更新数据库，再更新缓存
2. 先删除缓存，再更新数据库
3. 先更新数据库，再删除缓存

应该没人问我，为什么没有先更新缓存，再更新数据库这种策略。

### (1)先更新数据库，再更新缓存

这套方案，大家是普遍反对的。为什么呢？有如下两点原因。
**原因一（线程安全角度）**
同时有请求A和请求B进行更新操作，那么会出现
（1）线程A更新了数据库
（2）线程B更新了数据库
（3）线程B更新了缓存
（4）线程A更新了缓存
这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
**原因二（业务场景角度）**
有如下两点：
（1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
（2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。

接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。

### (2)先删缓存，再更新数据库

该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:
（1）请求A进行写操作，删除缓存
（2）请求B查询发现缓存不存在
（3）请求B去数据库查询得到旧值
（4）请求B将旧值写入缓存
（5）请求A将新值写入数据库
上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。
那么，**如何解决呢？采用延时双删策略**
伪代码如下

```
public void write(String key,Object data){
        redis.delKey(key);
        db.updateData(data);
        Thread.sleep(1000);
        redis.delKey(key);
    }
```

转化为中文描述就是
（1）先淘汰缓存
（2）再写数据库（这两步和原来一样）
（3）休眠1秒，再次淘汰缓存
这么做，可以将1秒内所造成的缓存脏数据，再次删除。
**那么，这个1秒怎么确定的，具体该休眠多久呢？**
针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。
**如果你用了mysql的读写分离架构怎么办？**
ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。
（1）请求A进行写操作，删除缓存
（2）请求A将数据写入数据库了，
（3）请求B查询缓存发现，缓存没有值
（4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
（5）请求B将旧值写入缓存
（6）数据库完成主从同步，从库变为新值
上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。
**采用这种同步淘汰策略，吞吐量降低怎么办？**
ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。
**第二次删除,如果删除失败怎么办？**
这是个非常好的问题，因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：
（1）请求A进行写操作，删除缓存
（2）请求B查询发现缓存不存在
（3）请求B去数据库查询得到旧值
（4）请求B将旧值写入缓存
（5）请求A将新值写入数据库
（6）请求A试图去删除请求B写入对缓存值，结果失败了。
ok,这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。
**如何解决呢？**
具体解决方案，且看博主对第(3)种更新策略的解析。

### (3)先更新数据库，再删缓存

首先，先说一下。老外提出了一个缓存更新套路，名为[《Cache-Aside pattern》](https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside)。其中就指出

- **失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- **命中**：应用程序从cache中取数据，取到后返回。
- **更新**：先把数据存到数据库中，成功后，再让缓存失效。

![Redis常见面试题 - 第7张  | 张嘎](https://i2.wp.com/images.cnblogs.com/cnblogs_com/rjzheng/1202350/o_update1.png?w=640&ssl=1)

![Redis常见面试题 - 第8张  | 张嘎](https://i0.wp.com/images.cnblogs.com/cnblogs_com/rjzheng/1202350/o_update2.png?w=640&ssl=1)

另外，知名社交网站facebook也在论文[《Scaling Memcache at Facebook》](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)中提出，他们用的也是先更新数据库，再删缓存的策略。
**这种情况不存在并发问题么？**
不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生
（1）缓存刚好失效
（2）请求A查询数据库，得一个旧值
（3）请求B将新值写入数据库
（4）请求B删除缓存
（5）请求A将查到的旧值写入缓存
ok，如果发生上述情况，确实是会发生脏数据。
**然而，发生这种情况的概率又有多少呢？**
发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。
假设，有人非要抬杠，有强迫症，一定要解决怎么办？
**如何解决上述并发问题？**
首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。
**还有其他造成不一致的原因么？**
有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。
**如何解决？**
提供一个保障的重试机制即可，这里给出两套方案。
**方案一**：
如下图所示

流程如下所示
（1）更新数据库数据；
（2）缓存因为种种问题删除失败
（3）将需要删除的key发送至消息队列
（4）自己消费消息，获得需要删除的key
（5）继续重试删除操作，直到成功
然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。
**方案二**：

流程如下图所示：
（1）更新数据库数据
（2）数据库会将操作信息写入binlog日志当中
（3）订阅程序提取出所需要的数据以及key
（4）另起一段非业务代码，获得该信息
（5）尝试删除缓存操作，发现删除失败
（6）将这些信息发送至消息队列
（7）重新从消息队列中获得该数据，重试操作。

**备注说明：**上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。至于oracle中，博主目前不知道有没有现成中间件可以使用。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。

## 总结

本文其实是对目前互联网中已有的一致性方案，进行了一个总结。对于先删缓存，再更新数据库的更新策略，还有方案提出维护一个内存队列的方式，博主看了一下，觉得实现异常复杂，没有必要，因此没有必要在文中给出。最后，希望大家有所收获。

## 参考文献

1、[主从DB与cache一致性](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=404308725&idx=1&sn=1a25ce76dd1956014ceb8a011855268e&scene=21#wechat_redirect)
2、[缓存更新的套路](https://coolshell.cn/articles/17416.html)
